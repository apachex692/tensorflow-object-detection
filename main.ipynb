{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmE_vUBFsj0f"
   },
   "source": [
    "# Tensorflow Object Detection\n",
    "\n",
    "- **Author:** Sakthi Santhosh\n",
    "- **Created on:** 21/08/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YoIuVnz2VHH"
   },
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z65nf46osnXp"
   },
   "outputs": [],
   "source": [
    "from cv2 import (\n",
    "    COLOR_BGR2RGB,\n",
    "    VideoCapture,\n",
    "    imwrite,\n",
    "    imread,\n",
    "    cvtColor\n",
    ")\n",
    "from os import path\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HovC55Gusq42"
   },
   "source": [
    "## Global Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jON_BaFzsvBX"
   },
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    \"capture\": \"./workspace/camera\",\n",
    "    \"testing\": (\n",
    "        \"./workspace/testing\",\n",
    "        \"./workspace/testing/images\",\n",
    "        \"./workspace/testing/annotations\"\n",
    "    ),\n",
    "    \"training\": (\n",
    "        \"./workspace/training\",\n",
    "        \"./workspace/training/images\",\n",
    "        \"./workspace/training/annotations\"\n",
    "    ),\n",
    "    \"export\": (\n",
    "        \"./workspace/export\",\n",
    "        \"./workspace/export/tflite\"\n",
    "    ),\n",
    "    \"label_map\": \"./workspace/label_map.pbtxt\",\n",
    "    \"pretrained_model\": \"./models/pretrained\",\n",
    "    \"custom_model\": \"./models/custom\",\n",
    "    \"tools\": \"./tools/research/object_detection\",\n",
    "    \"output\": \"./workspace/output\",\n",
    "    \"record\": \"./workspace/record\"\n",
    "}\n",
    "\n",
    "CAPTURE_COUNT = 12\n",
    "DETECTION_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bw4zxHkLsxXv"
   },
   "source": [
    "## Create Label and Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lw0OF86bs0Ug"
   },
   "outputs": [],
   "source": [
    "with open(\"./objects.txt\", 'r') as file_handle:\n",
    "    LABELS = tuple(map(str.strip, file_handle.readlines()))\n",
    "\n",
    "LABEL_MAP = []\n",
    "for index, label in enumerate(LABELS, start=1):\n",
    "    LABEL_MAP.append({\n",
    "        \"name\": label,\n",
    "        \"id\": index\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsLcvxu0s3hm"
   },
   "source": [
    "## Setup Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uMVZ2EPs77w"
   },
   "outputs": [],
   "source": [
    "if not path.exists(\"./workspace\"):\n",
    "    !mkdir ./workspace/ {PATHS[\"export\"][0]} {PATHS[\"export\"][1]} \\\n",
    "        {PATHS[\"output\"]} {PATHS[\"record\"]}\n",
    "\n",
    "if not path.exists(\"./models\"):\n",
    "    !mkdir ./models/ {PATHS[\"pretrained_model\"]} {PATHS[\"custom_model\"]}\n",
    "\n",
    "if not path.exists(\"./tools\"):\n",
    "    !mkdir ./tools/\n",
    "\n",
    "if not path.exists(PATHS[\"capture\"]):\n",
    "    !mkdir {PATHS[\"capture\"]}\n",
    "\n",
    "if not path.exists(PATHS[\"output\"]):\n",
    "    !mkdir {PATHS[\"output\"]}\n",
    "\n",
    "if not path.exists(PATHS[\"testing\"][0]):\n",
    "    !mkdir {PATHS[\"testing\"][0]} {PATHS[\"testing\"][1]} {PATHS[\"testing\"][2]}\n",
    "\n",
    "if not path.exists(PATHS[\"training\"][0]):\n",
    "    !mkdir {PATHS[\"training\"][0]} {PATHS[\"training\"][1]} {PATHS[\"training\"][2]}\n",
    "\n",
    "for label in LABELS:\n",
    "    folder = path.join(PATHS[\"capture\"], label)\n",
    "    if not path.exists(folder):\n",
    "        !mkdir {folder} {path.join(folder, \"images\")} {path.join(folder, \"annotations\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkcqI0F1tCeh"
   },
   "source": [
    "## Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAW-YLLBtFHr"
   },
   "outputs": [],
   "source": [
    "camera_handle = VideoCapture(0)\n",
    "for label in LABELS:\n",
    "    print(\"\\033[30;01mImage Capture (%s)\\033[00m\"%(label))\n",
    "    for counter in range(1, CAPTURE_COUNT + 1):\n",
    "        success, frame = camera_handle.read()\n",
    "        if not success:\n",
    "            print(\"  \\033[31;01mError:\\033[00m Image capture failed.\")\n",
    "            break\n",
    "        print(\"  %s_image%d.jpg.\"%(label, counter))\n",
    "        imwrite(\n",
    "            path.join(PATHS[\"capture\"], label, \"images\", label + \"_image%d.jpg\"%(counter)),\n",
    "            frame\n",
    "        )\n",
    "        sleep(2)\n",
    "    print()\n",
    "    sleep(5)\n",
    "\n",
    "camera_handle.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nwllMhNtGsX"
   },
   "source": [
    "## Annotating Images\n",
    "\n",
    "- Annotate the images with [Make Sense](https://makesense.ai).\n",
    "- Set the project's name to \"images\".\n",
    "- After downloading the annotations, place them in their respective folders.\n",
    "- Change the `<path>` tag to location of the corresponding image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpPBcjaRtRpQ"
   },
   "source": [
    "## Copy Files for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10BrbcYdtS71"
   },
   "outputs": [],
   "source": [
    "for label in LABELS:\n",
    "    folder1 = path.join(PATHS[\"capture\"], label, \"images\")\n",
    "    folder2 = path.join(PATHS[\"capture\"], label, \"annotations\")\n",
    "\n",
    "    for counter in range(1, CAPTURE_COUNT + 1, 3):\n",
    "        !cp {path.join(folder1, label + \"_image%d.jpg\"%(counter))} \\\n",
    "            {path.join(folder1, label + \"_image%d.jpg\"%(counter + 1))} \\\n",
    "            {PATHS[\"training\"][1]}\n",
    "        !cp {path.join(folder2, label + \"_image%d.xml\"%(counter))} \\\n",
    "            {path.join(folder2, label + \"_image%d.xml\"%(counter + 1))} \\\n",
    "            {PATHS[\"training\"][2]}\n",
    "\n",
    "    for counter in range(3, CAPTURE_COUNT + 1, 3):\n",
    "        !cp {path.join(folder1, label + \"_image%d.jpg\"%(counter))} \\\n",
    "            {PATHS[\"testing\"][1]}\n",
    "        !cp {path.join(folder2, label + \"_image%d.xml\"%(counter))} \\\n",
    "            {PATHS[\"testing\"][2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjQnjVk1tc8f"
   },
   "source": [
    "## Download Models and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtNAAh3OG8BW"
   },
   "outputs": [],
   "source": [
    "!wget -O ./models/pretrained/model.tar.gz \\\n",
    "    http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "!tar -x -z -f ./models/pretrained/model.tar.gz -C ./models/pretrained/\n",
    "\n",
    "!git clone https://github.com/tensorflow/models ./tools/\n",
    "!cd ./tools/research/ && protoc ./object_detection/protos/*.proto --python_out=./\n",
    "\n",
    "!cp ./tools/research/object_detection/packages/tf2/setup.py ./tools/research/ \\\n",
    "    && python3 -m pip install ./tools/research\n",
    "\n",
    "!python3 ./tools/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FFMp9VutlsR"
   },
   "source": [
    "## Create Label Map File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RE4mK8nJtka4"
   },
   "outputs": [],
   "source": [
    "with open(PATHS[\"label_map\"], 'w') as file_handle:\n",
    "    for label_map in LABEL_MAP:\n",
    "        file_handle.write(\"item {\\n\")\n",
    "        file_handle.write(\"\\tname: \\\"%s\\\"\\n\"%(label_map[\"name\"]))\n",
    "        file_handle.write(\"\\tid: %d\\n}\\n\"%(label_map[\"id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-nFNhiktpPD"
   },
   "source": [
    "## Create Tensorflow Records From Images and Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhH-u1aCRFRJ"
   },
   "outputs": [],
   "source": [
    "!python3 ./scripts/record.py {PATHS[\"testing\"][0]}/images/ \\\n",
    "    {PATHS[\"testing\"][0]}/annotations/ {PATHS[\"label_map\"]} \\\n",
    "    {PATHS[\"record\"]}/test.record\n",
    "\n",
    "!python3 ./scripts/record.py {PATHS[\"training\"][0]}/images/ \\\n",
    "    {PATHS[\"training\"][0]}/annotations/ {PATHS[\"label_map\"]} \\\n",
    "    {PATHS[\"record\"]}/train.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SczoWqITtx1Q"
   },
   "source": [
    "## Copy Pipeline File From Pretrained Model to Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZo5g0boTa-Y"
   },
   "outputs": [],
   "source": [
    "!cp {PATHS[\"pretrained_model\"]}/ssd_mobilenet_v2_fpnlite_320x320/pipeline.config \\\n",
    "    {PATHS[\"custom_model\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jwl7R1OZt2-9"
   },
   "source": [
    "## Modify Config File for Custom Model\n",
    "\n",
    "### Parameters to Change\n",
    "\n",
    "- `num_classes`: According to number of objects.\n",
    "- `batch_size`: 2-4\n",
    "- `fine_tune_checkpoint`: ./models/pretrained/ssd_mobilenet_v2_fpnlite_320x320/checkpoint/ckpt-0\n",
    "- `fine_tune_checkpoint_type`: detection\n",
    "- `label_map_path`: ./workspace/label_map.pbtxt\n",
    "- `tf_record_input_reader.input_path`: ./workspace/record/train.record\n",
    "- `eval_input_reader.label_map_path`: ./workspace/label_map.pbtxt\n",
    "- `eval_input_reader.tf_record_input_reader.input_path`: ./workspace/record/test.record\n",
    "- Optionally, one can change the parameter `total_steps` to increase/decrease the number of steps to train the model or specify it as a parameter before training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvn6i4ONt40Y"
   },
   "source": [
    "## Train the Model (Finally!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-9FsDwSUozI"
   },
   "outputs": [],
   "source": [
    "!python3 ./tools/research/object_detection/model_main_tf2.py \\\n",
    "    --model_dir={PATHS[\"custom_model\"]} \\\n",
    "    --pipeline_config_path={PATHS[\"custom_model\"]}/pipeline.config \\\n",
    "    --num_train_steps=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s21l52JTuBw6"
   },
   "source": [
    "## Evaluate the Model (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znO49B2zU1sI"
   },
   "outputs": [],
   "source": [
    "!python3 ./tools/research/object_detection/model_main_tf2.py \\\n",
    "    --model_dir={PATHS[\"custom_model\"]} \\\n",
    "    --pipeline_config_path={PATHS[\"custom_model\"]}/pipeline.config \\\n",
    "    --checkpoint_dir={PATHS[\"custom_model\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJK2iDFIuIZh"
   },
   "source": [
    "## Load Trained Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TYvd7n0uMMK"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "from numpy import array, expand_dims, int64\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import (\n",
    "    config_util,\n",
    "    label_map_util,\n",
    "    visualization_utils\n",
    ")\n",
    "import tensorflow\n",
    "\n",
    "configs = config_util.get_configs_from_pipeline_file(\n",
    "    path.join(PATHS[\"custom_model\"], \"pipeline.config\")\n",
    ")\n",
    "detection_model = model_builder.build(model_config=configs[\"model\"], is_training=False)\n",
    "\n",
    "checkpoint = tensorflow.compat.v2.train.Checkpoint(model=detection_model)\n",
    "checkpoint.restore(path.join(PATHS[\"custom_model\"], \"ckpt-3\")).expect_partial()\n",
    "\n",
    "@tensorflow.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCnX9UHyuQbX"
   },
   "source": [
    "## Image Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbY-gfHMuPQ6"
   },
   "outputs": [],
   "source": [
    "def detect_image(image_file):\n",
    "    count = 0\n",
    "    image_handle = imread(image_file)\n",
    "    image_array = array(image_handle)\n",
    "    image_expanded = expand_dims(image_array, axis=0)\n",
    "\n",
    "    input_tensor = tensorflow.convert_to_tensor(image_expanded, dtype=tensorflow.float32)\n",
    "    detection = detect_fn(input_tensor)\n",
    "\n",
    "    detection_count = int(detection.pop(\"num_detections\"))\n",
    "    detection = {key: value[0, :detection_count].numpy() for key, value in detection.items()}\n",
    "    detection[\"num_detections\"] = detection_count\n",
    "\n",
    "    detection[\"detection_classes\"] = detection[\"detection_classes\"].astype(int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_array_with_detections = image_array.copy()\n",
    "\n",
    "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_array_with_detections,\n",
    "        detection[\"detection_boxes\"],\n",
    "        detection[\"detection_classes\"] + label_id_offset,\n",
    "        detection[\"detection_scores\"],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=5,\n",
    "        min_score_thresh=DETECTION_THRESHOLD,\n",
    "        line_thickness=20,\n",
    "        agnostic_mode=False\n",
    "    )\n",
    "    pyplot.savefig(path.join(PATHS[\"output\"], path.basename(image_file)))\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATHS[\"label_map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm2HoykMuWOO"
   },
   "source": [
    "## Detecting Objects From Saved Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8j52EwyubeW"
   },
   "outputs": [],
   "source": [
    "for label in LABELS:\n",
    "    for counter in range(3, CAPTURE_COUNT + 1, 3):\n",
    "        detect_image(path.join(PATHS[\"testing\"][1], label + \"_image%d.jpg\"%(counter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UB0IUQ1ucoG"
   },
   "source": [
    "## Freezing the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkEXFtxBsapi"
   },
   "outputs": [],
   "source": [
    "!python3 ./tools/research/object_detection/exporter_main_v2.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={PATHS[\"custom_model\"]}/pipeline.config \\\n",
    "    --trained_checkpoint_dir={PATHS[\"custom_model\"]} \\\n",
    "    --output_directory={PATHS[\"export\"][0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZwC_HfUugDs"
   },
   "source": [
    "## Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxja_og9s3sD"
   },
   "outputs": [],
   "source": [
    "!python3 ./tools/research/object_detection/export_tflite_graph_tf2.py \\\n",
    "    --pipeline_config_path={PATHS[\"custom_model\"]}/pipeline.config \\\n",
    "    --trained_checkpoint_dir={PATHS[\"custom_model\"]} \\\n",
    "    --output_directory={PATHS[\"export\"][1]}\n",
    "\n",
    "!tflite_convert --saved_model_dir={PATHS[\"export\"][1]}/saved_model/ \\\n",
    "    --output_file={PATHS[\"export\"][1]}/saved_model/custom.tflite \\\n",
    "    --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor \\\n",
    "    --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1', \\\n",
    "        'TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "    --inference_type=FLOAT --allow_custom_ops"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
